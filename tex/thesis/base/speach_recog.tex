\section{アンカーの発話区間の音声認識実験}

\subsection{実験方法}
本実験では、\ref{section:yoshimura_pre_clustering}節で述べた話者クラスタを作成、音響モデルを作成して音声認識実験を行う。各話者クラスタに含まれる男女の発話データ数を図\ref{fig:yoshimura_kikouzou}に示す。

\begin{figure}[H]
  \begin{center}
    \includegraphics{./figure/kakiokosi.eps}
  \end{center}
  \caption{各話者クラスタに含まれる発話データ数 \label{fig:yoshimura_kikouzou}}
\end{figure}

本実験で使用した音響モデル、言語モデル、単語辞書の仕様は\ref{section:experiment_acoustic_model}節、\ref{section:experiment_language_model}節で述べる。

\subsection{音響モデルの仕様}
\label{section:experiment_acoustic_model}
本実験で用いたDNN-HMM音響モデルの仕様を表\ref{table:acoustic_model_detail}に示す。この仕様に関しては小島らの研究\cite{kojima}で使用されたもので、状態数は3000、音響特徴の次元数は39次元(表\ref{acoustic_model_feature})、隠れ層の数は6層、各層における繰り返し学習数は5回、隠れ層のノード数は1024とした。以下に、DNNを用いた際の学習の手順を示す。

\begin{table}[H]
  \begin{center}
    \caption{音響モデルの仕様 \label{table:acoustic_model_detail}}
    \begin{tabular}{|c|c|c|} \hline
     状態数  & 使用した音素 & 混合数 \\ \hline
     3,000  & 27 & 16 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

\begin{table}[H]
  \begin{center}
    \caption{使用する音響特徴パラメータ \label{acoustic_model_feature}}
    \begin{tabular}{|c||c|} \hline
      特徴量 & 次元数\\ \hline
      MFCC & 12  \\ \hline
      POW & 1  \\ \hline
      $\Delta$MFCC & 12 \\ \hline
      $\Delta$POW & 1 \\ \hline
      $\Delta\Delta$MFCC & 12 \\ \hline
      $\Delta\Delta$POW & 1 \\ \hline
      計 & 39 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

\vspace{0.2in}\noindent{\textbf{\underline{構築手順}}}\par
DNNを用いた音響モデルの構築や、この音響モデルを用いた音声認識に必要な学習テキストや言語モデルを作成する為にKaldiツールキットを用いた\cite{kaldi}。このツールキットの大きな流れを図\ref{fig:flow_train_dnn}に示す。まず学習や評価に必要なデータを用意し、言語モデルと単語辞書のWeighted Finite State Transducer （WFST）を作成する。WFSTとは重み付き有限トランスデューサといい、状態遷移機械モデル有限オートマトンの一種である。次に音声データから特徴量を抽出したデータを準備し、このデータと書き起こしを用いてGMM-HMMによる音響モデルのWFSTを作成する。これらのWFSTを、合成等を行ない1つのWFSTとする。このWFSTを用いて音声認識を行ない、学習データのアライメント（フレームごとの音素情報）をとる。このアライメントを用いてDNNを用いた音響モデルの学習（プレトレーニングと微調整）を行ない、最終的な音声認識を行なう。

\begin{figure}[H]
  \begin{center}
    \includegraphics{./figure/flow_train_dnn.eps}
  \end{center}
  \caption{DNNを用いる際の学習の流れ \label{fig:flow_train_dnn}}
\end{figure}

\vspace{0.2in}\noindent{\textbf{\underline{使用した音素}}}\par
本研究で使用した音素27個を表\ref{fig:used_onso}に示す。また、その音素をもとに記したカナ音素対応表を表\ref{fig:kana_onso}に示す


\begin{table}[H]
\begin{center}
\caption{使用した音素 \label{fig:used_onso}}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
母音  & 子音         & 濁音  & 半濁音 & 撥音 & 促音 & 無音 \\ \hline
a i & ch f h j k & b d &     &    &    &    \\ 
u e & m n r s sh & g z & p   & ng & q  & \# \\ 
o   & t ts w     & zh  &     &    &    &    \\ \hline
\end{tabular}
\end{center}
\end{table}


\begin{table}[H]
  \begin{center}
    \caption{カナ音素対応表 \label{fig:kana_onso}}
    \includegraphics[scale=0.7]{./figure/kana_onso.eps}
  \end{center}
  
\end{table}

\subsection{言語モデル・単語辞書の仕様}
\label{section:experiment_language_model}
言語モデルはトライグラムモデルを構築した。以下、使用した学習テキストを説明する。

\vspace{0.2in}\noindent{\textbf{\underline{CSJ}}}\par
CSJには書き起こしテキストも提供されており、その一部の例を図\ref{fig:kakiokosi}に示す。書き起こしテキストは主に情報部と発話部に区別される。情報部では発話IDや時間情報等を、発話部では発話内容を「＆」の左側に基本形、右側に発音形という形式で記している。発話形はカタカナを用いて実際に発音された音声を忠実に表記したものである。発音の怠けや言い間違い等を書き取れる範囲で忠実に記録している。本研究では、音響モデル構築の際には主に発話部の発音形を用い、このカタカナ表記を音素列に変換し、ラベルファイルとして定義する。
\begin{figure}[H]
  \begin{center}
    \includegraphics{./figure/kakiokosi.eps}
  \end{center}
  \caption{書き起こしテキストの例 \label{fig:kakiokosi}}
\end{figure}

本研究ではこのCSJをベースに学習テキストを構成する。使用するデータは977講演分のテキストで、約14MBである。

\vspace{0.2in}\noindent{\textbf{\underline{拡張したコーパスによる学習テキスト}}}\par
この学習テキストは江頭らによる、学術講演の書き起こしと新聞記事に拡張されるテキストとして参加者名の入ったテキスト、Webから収集してきたテキスト、そして対話コーパスから作成される対話テキストを追加した未知語の減少に着目した学習テキストである。この学習テキストは会議中に参加者の名前を呼ぶことが多い、会議は対話形式であるなどの会議の特徴を考慮した学習テキストである。テキストサイズは約100MBである。以降本論文では、このテキストを拡張したコーパスによる学習テキストと呼ぶ。

\vspace{0.2in}\noindent{\textbf{\underline{拡張したコーパスによる学習テキスト}}}\par
この学習テキストは荒井らによる、会議における発話行為に着目して作成された学習テキストである。学術講演の書き起こしと新聞記事に対話表現に近い特徴を持っていると考えられるQ＆Aサイトから収集したテキストと対話コーパスを追加した学習テキストである。テキストサイズは約44MBである。以降本論文ではこのテキストを対話特化テキストと呼ぶ。


\subsection{評価方法}
本研究では評価尺度としては式\ref{calc:word_acc}で与えられる単語正解精度$Acc$(Word Accuracy)を用いる。ここで$W$は単語数、$S$(Substitution)は置換誤り、$D$(Deletion)は脱落誤り、$I$(Insertions)は挿入誤りの単語数を表わす。置換誤りとは、正解の単語が別の単語に誤認識された場合の誤りである。脱落誤りとは、単語があるべき部分に認識結果が何も出力されなかった場合の誤りである。挿入誤りは、本来単語がない部分に誤認識結果として単語が出力された場合の誤りである。

\begin{equation}
\label{calc:word_acc}
Acc=\frac{(W-S-D-I)}{W}
\end{equation}

          
評価は、正解ファイルと認識結果のファイルをDPマッチングを行なうことにより算出する。この正解ファイルは形態素解析した結果の形態素列によって作成したものである。


また、本研究ではアンカーの発話区間が既知の場合と未知の場合で音声認識精度の評価を行う。ここで、アンカーの発話区間が未知の時、\ref{chapter:get_anchor}節で検出したアンカーの発話区間のうち、各手法でもっともF値の高かった結果を対象とした音声認識を行うため、アンカー以外の発話区間で認識された単語は全て挿入誤り、アンカーの発話として検出出来なかった発話区間の単語は全て削除誤りとして計算する。
\subsection{実験結果}
\noindent{\textbf{\underline{アンカーの発話区間が既知の場合}}}\par
アンカーの発話区間が既知の場合の音声認識結果を表\ref{table:result_sprecog1}に示す。

\begin{table}[H]
  \begin{center}
    \caption{アンカーの発話区間が既知の場合の音声認識結果 \label{table:result_sprecog1}}
    \begin{tabular}{|c||c|c|c|c|c|} \hline
     手法  & $Acc$  & Substitution & Deletion　& Insertions \\ \hline
     Baseline  & 61.6 & 463　& 307　& 1834 \\ \hline
     手法1  & 61.6  & 477　& 318　& 1813 \\ \hline
     手法2  & 61.7  & 460　& 305　& 1836\\ \hline
     手法3  & 61.6  & 460　& 304　& 1827 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

Baselineと比較して、いずれの手法も認識精度の向上は確認できなかった。

\vspace{0.2in}\noindent{\textbf{\underline{アンカーの発話区間が未知の場合}}}\par
アンカーの発話区間が未知の場合の音声認識結果を表\ref{table:result_sprecog2}に示す。

\begin{table}[H]
  \begin{center}
    \caption{アンカーの発話区間が未知の場合の音声認識結果 \label{table:result_sprecog2}}
    \begin{tabular}{|c||c|c|c|c|c|} \hline
     手法  & $Acc$ & Word & Substitution & Deletion　& Insertions \\ \hline
     Baseline  & 26.7  & 957　& 2334　& 1684 \\ \hline
     手法1  & 29.9  & 994　& 2080　& 1681 \\ \hline
     手法2  & 35.4  & 998　& 1713　& 1670\\ \hline
     手法3  & 35.4 & 998 & 1713　& 1670　& \\ \hline
    \end{tabular}
  \end{center}
\end{table}

アンカーの発話区間が未知の場合はいずれも発話区間が既知の場合と比較して大きく音声認識精度が低下した。また、いずれの手法もBaselineと比較して音声認識精度は向上している。
\subsection{考察}
アンカーの発話区間が既知の場合に音声認識精度がいずれも変化がなかった理由として、背景雑音、音楽の存在が考えられる。これは、音響モデルの学習に用いたCSJが声の入らない環境で収録を行っているため、雑音、音楽が同時になった状態の音声は収録されていない。このため、本実験で作成した木構造話者クラスの音響モデルのいずれも認識できない発話が多く存在してしまい、認識精度の違いがなかったと考えられる。そのため、音声認識精度の向上のために、雑音除去、もしくは雑音、音楽に頑健な音響モデルの作成が必要であると考えらえる。\par
アンカーの発話区間が未知の場合はいずれも発話区間が既知の場合と比較して大きく音声認識精度が低下した理由として、アンカー以外の発話区間で認識された単語は全て挿入誤り、アンカーの発話として検出出来なかった発話区間の単語は全て削除誤りとして計算したためである。また、いずれの手法もBaselineと比較してアンカーの発話区間検出精度が向上していたため、音声認識精度はいずれの手法もBaselineと比較して音声認識精度は向上している。
